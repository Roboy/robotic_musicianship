{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pypianoroll as ppr\n",
    "import time\n",
    "import music21\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from utils.utils import *\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "#torch.set_printoptions(threshold=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########HYPERPARAMS#####################\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0.999\n",
    "batch_size = 1 #CHANGE THIS VERWRIRUNG\n",
    "seq_length = 8\n",
    "log_interval = 10 #Log/show loss per batch\n",
    "input_size=100\n",
    "hidden_size=128\n",
    "##########################################\n",
    "##########################################\n",
    "batch_loader = batch_size * seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../YamahaPianoCompetition2002NoTranspose.npz')\n",
    "#midiDatasetTrain = data['train']\n",
    "midiDatasetTest = data['test']\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midiDatasetTrain = torch.from_numpy(midiDatasetTrain)\n",
    "#trainLoader = torch.utils.data.DataLoader(midiDatasetTrain, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "midiDatasetTest = torch.from_numpy(midiDatasetTest)\n",
    "testLoader = torch.utils.data.DataLoader(midiDatasetTest, batch_size=batch_loader, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.LSTM import LSTM_Many2Many\n",
    "from utils.VAE import VAE\n",
    "from loadModel import loadModel\n",
    "\n",
    "#for gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#load models\n",
    "lstmModel = LSTM_Many2Many(batch_size=batch_loader, seq_length=seq_length, \n",
    "             input_size=input_size, hidden_size=hidden_size)\n",
    "autoencoderModel = VAE()\n",
    "\n",
    "#load weights\n",
    "lstmModel = loadModel(lstmModel, '../../new_models_and_plots/LSTM_WikifoniaTP12_128hidden_180epochs_LRe-4_Many2Many.model')\n",
    "autoencoderModel = loadModel(autoencoderModel, \n",
    "                             '../../new_models_and_plots/YamahaPC2002_VAE_Reconstruct_NoTW_20Epochs.model',\n",
    "                            dataParallelModel=False)\n",
    "# to device\n",
    "lstmModel = lstmModel.double().to(device)\n",
    "autoencoderModel = autoencoderModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new sample by feeding 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "playSeq = 8\n",
    "lstmModel.batch_size = int(batch_loader/2)\n",
    "lstmModel.seq_length = int(seq_length/2)\n",
    "interact_seq_legnth = int(seq_length/2)  # 4 \n",
    "\n",
    "if(lstmModel.train()):\n",
    "    lstmModel.eval()\n",
    "if(autoencoderModel.train()):\n",
    "    autoencoderModel.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for pathToSampleSeq in glob.glob('../../WikifoniaServer/test/*.mid'):\n",
    "        sampleNp1 = getSlicedPianorollMatrixNp(pathToSampleSeq)\n",
    "        sampleNp1 = deleteZeroMatrices(sampleNp1)\n",
    "        sample = np.expand_dims(sampleNp1[0,:,36:-32],axis=0)\n",
    "        #print(sample.shape)\n",
    "        for i, sampleNp in enumerate(sampleNp1[playSeq:playSeq+(interact_seq_legnth-1)]):\n",
    "            #print(sampleNp.shape)\n",
    "            if(np.any(sampleNp)):\n",
    "                sampleNp = sampleNp[:,36:-32]\n",
    "                sampleNp = np.expand_dims(sampleNp,axis=0)\n",
    "                sample = np.concatenate((sample,sampleNp),axis=0)\n",
    "        samplePlay = sample[0,:,:]\n",
    "        for s in sample[1:]:\n",
    "            samplePlay = np.concatenate((samplePlay,s),axis=0)\n",
    "        samplePlay = addCuttedOctaves(samplePlay)\n",
    "        #print(samplePlay.shape)\n",
    "        \n",
    "        #####PREPARE SAMPLE for input\n",
    "        sample = torch.from_numpy(sample).float().to(device)\n",
    "        sample = torch.unsqueeze(sample,1)\n",
    "#         print(sample.size())\n",
    "\n",
    "        #####MODEL##############\n",
    "        embed, _ = autoencoderModel.encoder(sample)\n",
    "#         print('embed.size() =', embed.size())\n",
    "        embed = embed.unsqueeze(0).double()\n",
    "        #print('embed.size() =', embed.size())\n",
    "\n",
    "        embed, lstmOut = lstmModel(embed, future=0)\n",
    "        lstmOut = lstmOut.float().squeeze(0)\n",
    "#         print(\"lstmOut.size()\", lstmOut.size())\n",
    "#         print(\"embed before decode\", embed.size())\n",
    "        recon = autoencoderModel.decoder(embed.squeeze(0).float())\n",
    "#         print(\"recon.size()\", recon.size())\n",
    "        pred = autoencoderModel.decoder(lstmOut)\n",
    "#         print(\"pred.size()\", pred.size())\n",
    "        ########################\n",
    "        \n",
    "        # reorder prediction\n",
    "        pred = pred.squeeze(1)\n",
    "        predict = pred[0]\n",
    "        for p in pred[1:]:\n",
    "            predict = torch.cat((predict, p), dim=0)\n",
    "#         print(predict.size()) \n",
    "        \n",
    "        #reorder reconstruction\n",
    "        recon = recon.squeeze(1)\n",
    "        reconstruction = recon[0]\n",
    "        for r in recon[1:]:\n",
    "            reconstruction = torch.cat((reconstruction, r), dim=0)\n",
    "#         print(\"reconstruction.size()\", reconstruction.size())\n",
    "        \n",
    "        predict = predict.cpu().numpy()\n",
    "        reconstruction = reconstruction.cpu().numpy()\n",
    "#         print(predict.shape)\n",
    "        #print(predict.shape)\n",
    "\n",
    "        #NORMALIZE PREDICTIONS\n",
    "        reconstruction /= np.abs(np.max(reconstruction))\n",
    "        prediction = predict\n",
    "        prediction /= np.abs(np.max(prediction))\n",
    "        #print(prediction)\n",
    "\n",
    "        #CHECK MIDI ACTIVATIONS IN PREDICTION TO INCLUDE RESTS\n",
    "        reconstruction[reconstruction < 0.3] = 0\n",
    "        prediction[prediction < 0.3] = 0\n",
    "        #print(prediction)\n",
    "\n",
    "        samplePlay = debinarizeMidi(samplePlay, prediction=False)\n",
    "        samplePlay = addCuttedOctaves(samplePlay)\n",
    "        reconstruction = debinarizeMidi(reconstruction, prediction=True)\n",
    "        reconstruction = addCuttedOctaves(reconstruction)\n",
    "        prediction = debinarizeMidi(prediction, prediction=True)\n",
    "        prediction = addCuttedOctaves(prediction)\n",
    "        print(\"INPUT\")\n",
    "        print(samplePlay.shape)\n",
    "        pianorollMatrixToTempMidi(samplePlay, show=True,showPlayer=True,autoplay=True)\n",
    "        print(\"RECONSTRUCTION\")\n",
    "        pianorollMatrixToTempMidi(reconstruction, show=True,\n",
    "                                   showPlayer=True,autoplay=True, prediction=True)\n",
    "        print(\"PREDICTION\")\n",
    "        pianorollMatrixToTempMidi(prediction, prediction=True, \n",
    "                                  show=True,showPlayer=True,autoplay=True)        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
