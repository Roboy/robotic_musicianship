{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import glob\n",
    "import pypianoroll as ppr\n",
    "import time\n",
    "import music21\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from utils.utilsPreprocessing import *\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "torch.set_printoptions(threshold=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#HYPERPARAMS\n",
    "##################################\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "batch_size= 14\n",
    "log_interval = 1  #Log/show loss per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MIDI files from npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (39782, 1, 96, 60)\n",
      "Test set: (9691, 1, 96, 60)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('../YamahaPianoCompetition2002NoTranspose.npz')\n",
    "\n",
    "midiDatasetTrain = data['train']\n",
    "midiDatasetTest = data['test']\n",
    "\n",
    "data.close()\n",
    "\n",
    "\"\"\"\n",
    "print(\"Training set: ({}, {}, {}, {})\".format(midiDatasetTrain.size()[0],\n",
    "                                                midiDatasetTrain.size()[1],\n",
    "                                                midiDatasetTrain.size()[2],\n",
    "                                                midiDatasetTrain.size()[3]))\n",
    "print(\"Test set: ({}, {}, {}, {})\".format(midiDatasetTest.size()[0],\n",
    "                                                midiDatasetTest.size()[1],\n",
    "                                                midiDatasetTest.size()[2],\n",
    "                                                midiDatasetTest.size()[3]))\n",
    "\"\"\"\n",
    "\n",
    "print(\"Training set: {}\".format(midiDatasetTrain.shape))\n",
    "print(\"Test set: {}\".format(midiDatasetTest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fullPitch = 128\n",
    "_, _, length, reducedPitch = midiDatasetTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------model restored--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.CDVAE import CDVAE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "autoencoderModel = CDVAE()\n",
    "#LOAD MODEL\n",
    "pathToModel = 'model/YamahaPianoCompetition2002Transposedby60_10Epochs.model'\n",
    "\n",
    "try:\n",
    "    #LOAD TRAINED MODEL INTO GPU\n",
    "    if(torch.cuda.is_available()):\n",
    "        autoencoderModel = torch.load(pathToModel)\n",
    "        \n",
    "    #LOAD MODEL TRAINED ON GPU INTO CPU\n",
    "    else:\n",
    "        autoencoderModel = torch.load(pathToModel, map_location=lambda storage, loc: storage)\n",
    "    print(\"\\n--------model restored--------\\n\")\n",
    "except:\n",
    "    print(\"\\n--------no saved model found--------\\n\")\n",
    "autoencoderModel = autoencoderModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "midiDatasetTrain = torch.from_numpy(midiDatasetTrain)\n",
    "trainLoader = torch.utils.data.DataLoader(midiDatasetTrain, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "midiDatasetTest = torch.from_numpy(midiDatasetTest)\n",
    "testLoader = torch.utils.data.DataLoader(midiDatasetTest, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, batch_size=7, lstmLayers=2, hiddenSize=100):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hiddenSize\n",
    "        self.lstm_layers = lstmLayers\n",
    "        ###LSTM###########\n",
    "        self.embedding = nn.Embedding(100,1)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=100, hidden_size=self.hidden_size,\n",
    "                            num_layers=self.lstm_layers, batch_first=True, dropout=0.5)\n",
    "        ##################\n",
    "        ###LSTMCells######\n",
    "        self.lstmC1 = nn.LSTMCell(input_size=100, hidden_size=self.hidden_size, bias=True)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.lstmC2 = nn.LSTMCell(input_size=400, hidden_size=self.hidden_size, bias=True)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.lstmC3 = nn.LSTMCell(input_size=400, hidden_size=self.hidden_size, bias=True)\n",
    "        #################\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size,100)\n",
    "        self.eluFC = nn.ELU()\n",
    "    \n",
    "    def splitEmbedding(self,embed):\n",
    "        if(embed.size()[0]>7):\n",
    "            embedTemp = torch.chunk(embed, int(self.batch_size/7),dim=0)\n",
    "            embed7s = embedTemp[0].unsqueeze(0)\n",
    "            for emb in embedTemp[1:]:\n",
    "                #print(\"inloop\");print(emb.unsqueeze(1).size())\n",
    "                embed7s = torch.cat((embed7s, emb.unsqueeze(0)),dim=0)\n",
    "                #print(\"afterconcat\");print(embed7s.size())\n",
    "        else:\n",
    "            embed7s = embed.unsqueeze(0)\n",
    "        return embed7s\n",
    "    \n",
    "    def hiddenInitLSTM(self,embed):\n",
    "        hiddenState = torch.zeros(self.lstm_layers,int(embed.size()[0]),self.hidden_size).to(device)\n",
    "        cellState = torch.zeros(self.lstm_layers,int(embed.size()[0]),self.hidden_size).to(device)\n",
    "        return hiddenState,cellState\n",
    "    \n",
    "    def hiddenInitLSTMCell(self,embed):\n",
    "        hiddenState = torch.zeros(int(embed.size()[0]/7),self.hidden_size).to(device)\n",
    "        cellState = torch.zeros(int(embed.size()[0]/7),self.hidden_size).to(device)\n",
    "        hS2 = torch.zeros(int(embed.size()[0]/7),self.hidden_size).to(device)\n",
    "        cS2 = torch.zeros(int(embed.size()[0]/7),self.hidden_size).to(device)\n",
    "        \n",
    "        return (hiddenState, cellState), (hS2, cS2)\n",
    "\n",
    "    def forward(self, embed):\n",
    "\n",
    "        h_t, c_t = self.hiddenInitLSTM(embed)\n",
    "        #(h_t, c_t),(h2_t, c2_t) = self.hiddenInitLSTMCell(embed)\n",
    "        #print(h_t.size())\n",
    "        ###LSTMCells######\n",
    "        #print(embed.size())\n",
    "        if(embed.size()[0]==7):\n",
    "            embed = embed.unsqueeze(1)\n",
    "        #print(embed.size())\n",
    "        \"\"\"\n",
    "        output = []\n",
    "        for i in range(7):\n",
    "            h_t, c_t = self.lstmC1(embed[i],(h_t,c_t))\n",
    "            #print(h_t.size())\n",
    "            #h_t = self.drop1(h_t)\n",
    "            #h2_t, c2_t = self.lstmC2(h_t,(h2_t,c2_t))\n",
    "            \n",
    "            output.append(h_t)\n",
    "        #h_t = nn.Dropout(h_t)\n",
    "        #h_t, c_t = self.lstmC2(h_t)\n",
    "        lstmOut = torch.Tensor(7,100).to(device)\n",
    "        lstmOut = torch.cat(output)\n",
    "        \n",
    "        #print(\"lstmout\");print(lstmOut.size())\n",
    "        \"\"\"\n",
    "        print(embed.size())\n",
    "        ###LSTM###########\n",
    "        print(embed[0])\n",
    "        embed = self.embedding(embed.long())\n",
    "        print(embed[0].squeeze(2))\n",
    "        lstmOut, (h_t, c_t) = self.lstm(embed,(h_t, c_t))\n",
    "        print('embedding');print(embed[0,1,:20]);print('lstmOut');print(lstmOut[0,0,:20])\n",
    "        ##################\n",
    "        \n",
    "        lstmOut = self.fc(lstmOut)\n",
    "        \n",
    "        #print(embed)\n",
    "        #print(lstmOut)\n",
    "        \n",
    "        #lstmOut = self.eluFC(lstmOut)\n",
    "        if(embed.size()[0]==7):\n",
    "            embed = embed.squeeze(1)\n",
    "        return embed, lstmOut\n",
    "\n",
    "    \n",
    "\n",
    "model = LSTM(batch_size=batch_size).to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=learning_rate, weight_decay=0.9)\n",
    "\n",
    "def loss_function(embed, lstmOut):\n",
    "    \n",
    "    cosLSTM = nn.CosineSimilarity(dim=1, eps=1e-8) \n",
    "    batch_sizeMin1 = embed.size()[0]-1\n",
    "    MSELoss = nn.MSELoss(reduction='sum')\n",
    "    #BATCHSIZE 7\n",
    "    ###WRONG SINCE LOSS CHANGED TO COMPARE EVERY\n",
    "    ###PREDICTED SEQUENCE WITH THE NEXT\n",
    "    if(embed.size()[0]==7):\n",
    "        #print(\"loss\");print(embed.size());print(lstmOut.size())\n",
    "        cosSimLSTM = torch.sum(cosLSTM(embed[1:],lstmOut[:-1]))\n",
    "        totalLoss = batch_sizeMin1 - cosSimLSTM\n",
    "     \n",
    "    #BATCHSIZE > 7\n",
    "    else:\n",
    "        print(\"LOSS\")\n",
    "        print(embed.size());print(lstmOut.size())\n",
    "        \"\"\"\n",
    "        cosSimLSTM = 0\n",
    "        for emb, lOut in zip(embed,lstmOut):\n",
    "            print(emb[1:].size());print(lOut[:-1].size())\n",
    "            print(cosLSTM(emb[1:],lOut[:-1]))\n",
    "            cosSimLSTM += torch.sum(cosLSTM(emb[1:],lOut[:-1]))\n",
    "        print(cosSimLSTM)\n",
    "        numberCosSims = embed.size()[0]*(embed.size()[1]-1)\n",
    "        #print(numberCosSims)\n",
    "        totalLoss = numberCosSims - cosSimLSTM\n",
    "        \"\"\"\n",
    "\n",
    "        mseLSTM = MSELoss(lstmOut[:,:-1,:],embed[:,1:,:])\n",
    "        totalLoss = mseLSTM / (embed.size()[0]*(embed.size()[1]-1))\n",
    "        \n",
    "        \n",
    "    return totalLoss\n",
    "        \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    trainLoss = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(trainLoader):\n",
    "        #print(batch_idx)\n",
    "        data = data.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embedding = autoencoderModel.encoder(data)\n",
    "        embedding = model.splitEmbedding(embedding)\n",
    "        #print(embedding.size())\n",
    "        embedding, lstmOut = model(embedding)\n",
    "        loss = loss_function(embedding, lstmOut)\n",
    "        \n",
    "        ###LSTM###############\n",
    "        #reconPrediction = autoencoderModel.decoder(lstmOut[:,-1,:])\n",
    "        ######################\n",
    "        ###LSTMCell###########\n",
    "        #reconPrediction = autoencoderModel.decoder(lstmOut)\n",
    "        ######################\n",
    "\n",
    "        loss.backward()\n",
    "        trainLoss += loss.item()\n",
    "        optimizer.step()\n",
    "        if(batch_idx % log_interval == 0):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainLoader.dataset),\n",
    "                100. * batch_idx / len(trainLoader),\n",
    "                loss.item() / (len(data)-(model.batch_size/7))))\n",
    "        #if(batch_idx==1):\n",
    "        #   break\n",
    "    print('====> Epoch: {} Average Loss: {:.4f}'.format(\n",
    "          epoch, trainLoss / (len(trainLoader.dataset)-batch_idx*(model.batch_size/7))))\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    testLoss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testLoader):\n",
    "            data = data.float().to(device)\n",
    "            embedding = autoencoderModel.encoder(data)\n",
    "            #embedding = model.splitEmbedding(embedding)\n",
    "            embedding, lstmOut = model(embedding)\n",
    "            loss = loss_function(embedding, lstmOut)\n",
    "            ###LSTM#########\n",
    "            #reconPrediction = autoencoderModel.decoder(lstmOut[:,-1,:])\n",
    "            ################\n",
    "            ###LSTMCell#####\n",
    "            reconPrediction = autoencoderModel.decoder(lstmOut)\n",
    "            ################\n",
    "            testLoss += loss_function(embedding, lstmOut).item()\n",
    "            \n",
    "            #if(i==1):\n",
    "            #    break\n",
    "    testLoss /= (len(testLoader.dataset)-i*(model.batch_size/7))\n",
    "\n",
    "    print('====> Test set Loss: {:.4f}'.format(testLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#LOAD MODEL\n",
    "pathToModel = '../models/WikifoniaNoTranpose_10Epochs_LSTM_noTW_dropout50.model'\n",
    "\n",
    "try:\n",
    "    #LOAD TRAINED MODEL INTO GPU\n",
    "    if(torch.cuda.is_available()):\n",
    "        model = torch.load(pathToModel)\n",
    "        \n",
    "    #LOAD MODEL TRAINED ON GPU INTO CPU\n",
    "    else:\n",
    "        model = torch.load(pathToModel, map_location=lambda storage, loc: storage)\n",
    "    print(\"\\n--------model restored--------\\n\")\n",
    "except:\n",
    "    print(\"\\n--------no saved model found--------\\n\")\n",
    "\"\"\"\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 100])\n",
      "tensor([[2.5448, 1.9012, 2.0805, 1.3013, 1.6549, 2.0362, 1.6548, 2.6756, 1.4527,\n",
      "         1.5936, 1.8229, 1.4256, 1.0402, 1.7841, 0.3481, 2.0761, 2.0810, 1.5436,\n",
      "         1.5320, 2.9451, 0.7784, 1.7424, 1.4497, 1.5300, 2.1819, 1.4154, 2.1641,\n",
      "         1.4190, 0.7857, 1.6166, 1.7055, 2.5857, 1.7286, 1.9286, 1.5975, 1.8182,\n",
      "         1.0389, 2.1091, 1.5535, 2.1466, 2.2400, 2.0019, 2.5337, 0.5830, 1.9268,\n",
      "         2.3171, 0.7730, 1.9442, 1.7191, 0.4469, 1.8385, 1.3577, 2.2958, 2.1344,\n",
      "         1.3279, 2.0894, 1.8719, 1.2606, 2.3819, 1.4657, 1.5775, 2.1000, 1.7351,\n",
      "         1.2304, 0.6315, 1.2131, 2.2732, 1.8445, 1.7833, 1.2896, 1.9840, 1.3908,\n",
      "         2.4299, 1.8995, 2.3911, 0.8352, 1.7965, 1.9803, 1.9781, 2.4562, 2.2378,\n",
      "         1.3083, 1.1804, 1.4861, 1.5230, 2.0371, 2.1190, 2.2801, 1.2843, 1.2626,\n",
      "         1.3010, 2.0785, 1.0952, 2.0311, 1.5465, 0.7218, 2.1923, 1.4647, 2.4173,\n",
      "         0.7257],\n",
      "        [2.5621, 2.0696, 2.4994, 1.3108, 1.3814, 1.3434, 1.5317, 2.6236, 1.7355,\n",
      "         1.2486, 1.0510, 1.7933, 0.7399, 2.0753, 0.8147, 2.2757, 1.8063, 0.9929,\n",
      "         1.8749, 2.6874, 0.9483, 1.7270, 1.6941, 1.9370, 2.3218, 1.5161, 1.7249,\n",
      "         1.2402, 0.5737, 1.1111, 1.6876, 2.8956, 1.8410, 1.6743, 1.0195, 1.4230,\n",
      "         1.2385, 2.2668, 1.3727, 2.2948, 2.3179, 1.7019, 2.3878, 0.8060, 1.9236,\n",
      "         2.1808, 1.0528, 1.8033, 1.8036, 0.5160, 1.8715, 1.4424, 2.1822, 1.7240,\n",
      "         1.5442, 2.5483, 1.8268, 1.5954, 1.7407, 1.1909, 1.5424, 1.8986, 2.0582,\n",
      "         1.2634, 1.1285, 0.9983, 2.3219, 1.7202, 1.3934, 1.3485, 1.9814, 1.4131,\n",
      "         2.3043, 1.7209, 1.7621, 0.9462, 2.0185, 2.2876, 2.1611, 2.5792, 2.1585,\n",
      "         1.1687, 1.3526, 1.5207, 1.5935, 1.6281, 1.4858, 2.0186, 1.2840, 1.0999,\n",
      "         1.0006, 1.9372, 0.6045, 2.0538, 1.5302, 0.6757, 2.6470, 1.2797, 2.5737,\n",
      "         0.6195],\n",
      "        [2.5214, 1.3640, 1.7209, 1.9051, 1.1474, 1.3151, 1.5994, 2.3617, 1.5432,\n",
      "         1.8763, 1.7501, 1.2070, 0.9571, 2.2060, 0.6203, 1.6963, 1.9900, 0.8850,\n",
      "         2.3805, 1.9779, 1.0551, 2.1256, 1.6775, 1.7754, 2.0233, 1.6432, 1.7629,\n",
      "         1.8885, 1.4745, 2.0682, 1.4626, 2.2585, 2.1576, 1.0760, 1.3729, 1.6383,\n",
      "         1.0998, 2.8822, 1.7533, 2.0261, 1.5532, 1.0994, 2.1562, 1.0973, 2.0823,\n",
      "         2.3522, 1.8017, 0.8084, 1.9288, 1.0086, 1.5193, 1.7130, 1.2156, 1.6245,\n",
      "         1.1374, 2.1463, 1.8518, 0.9253, 1.2315, 0.6263, 1.8549, 1.8731, 1.7633,\n",
      "         1.7366, 2.1385, 1.4176, 1.4175, 2.2690, 1.8418, 1.2532, 1.9067, 1.0104,\n",
      "         2.6106, 2.0702, 1.7282, 1.5592, 1.5396, 2.4357, 1.2406, 2.7714, 1.2696,\n",
      "         1.7939, 1.6125, 1.1864, 2.2073, 2.0980, 1.2672, 2.1774, 0.8135, 1.8106,\n",
      "         1.0796, 1.3913, 0.8484, 1.9905, 2.0231, 0.5255, 1.5726, 1.5345, 2.4315,\n",
      "         0.9348],\n",
      "        [2.4303, 2.1880, 1.2972, 1.8722, 1.3037, 0.9351, 1.9475, 2.6966, 1.9207,\n",
      "         2.4600, 1.5229, 2.4074, 1.1889, 1.4330, 1.7558, 2.1567, 1.9909, 2.3870,\n",
      "         1.8568, 1.6814, 1.4641, 1.2601, 1.5808, 2.7644, 2.5185, 1.7764, 1.8282,\n",
      "         1.0510, 1.3319, 1.3726, 1.5595, 2.5454, 2.4751, 1.6353, 2.0152, 2.1400,\n",
      "         1.1841, 2.6713, 2.3774, 1.8355, 1.9979, 1.6183, 2.2317, 0.7338, 1.5940,\n",
      "         1.7952, 0.7540, 1.6916, 1.7794, 1.2730, 1.6707, 1.6135, 2.4409, 1.7616,\n",
      "         1.3525, 2.4080, 1.6667, 1.4335, 1.4476, 1.3520, 2.1422, 2.1432, 0.8765,\n",
      "         2.0547, 0.6547, 0.7242, 1.2602, 1.7840, 1.6378, 0.2492, 2.1346, 2.5886,\n",
      "         2.6073, 2.1672, 0.9581, 0.5541, 1.5988, 2.6384, 1.9132, 2.4627, 2.8666,\n",
      "         0.7610, 1.9862, 2.4320, 1.1987, 1.8420, 1.8615, 1.8344, 1.6940, 0.0623,\n",
      "         1.1716, 2.0927, 1.6242, 1.3352, 2.5447, 1.1190, 2.0351, 0.5887, 2.0588,\n",
      "         0.6422],\n",
      "        [2.0213, 1.4112, 1.6669, 1.5529, 1.4373, 1.7287, 1.6138, 1.8939, 1.6373,\n",
      "         1.5380, 2.0747, 1.2693, 0.8060, 1.8900, 1.2756, 2.0426, 1.7895, 1.3573,\n",
      "         1.4509, 1.3062, 1.4962, 2.0499, 1.9962, 1.7250, 2.1615, 1.2762, 1.8035,\n",
      "         1.7546, 1.5236, 1.5772, 1.4741, 2.1949, 1.4078, 0.8581, 1.1502, 1.0770,\n",
      "         1.3073, 2.0164, 1.2265, 1.3401, 1.0895, 1.3780, 1.3787, 1.0811, 1.7652,\n",
      "         1.6088, 1.8815, 0.8931, 2.1225, 1.0290, 1.5809, 1.4639, 1.5119, 1.9848,\n",
      "         1.3654, 1.6961, 1.9785, 1.1902, 0.9025, 1.2879, 1.8102, 1.8257, 2.2802,\n",
      "         2.4757, 1.8805, 1.6655, 1.6207, 1.5381, 1.9644, 2.0049, 1.8852, 1.6206,\n",
      "         2.2348, 1.7418, 1.9689, 1.5109, 1.7946, 2.0059, 1.7512, 1.9466, 1.0904,\n",
      "         1.2060, 1.3595, 1.2120, 1.5467, 2.4184, 1.7941, 1.7804, 1.2657, 1.9402,\n",
      "         1.8125, 1.5315, 1.6721, 1.7272, 1.6352, 1.6368, 1.9958, 1.1215, 1.6620,\n",
      "         1.5879],\n",
      "        [1.9663, 2.2342, 1.2614, 1.7148, 1.8624, 0.8439, 0.8546, 2.4912, 2.0403,\n",
      "         2.7943, 1.4301, 1.2044, 1.9436, 2.2542, 1.7977, 1.8152, 1.7775, 1.9705,\n",
      "         1.7664, 0.7664, 1.3329, 1.6769, 2.1753, 1.0364, 2.2598, 1.6688, 0.7740,\n",
      "         0.6711, 1.3236, 1.8945, 1.5214, 0.4748, 1.9628, 1.3457, 0.7064, 1.6620,\n",
      "         1.8935, 1.9013, 1.4387, 0.4361, 1.9571, 1.1804, 1.7972, 1.6499, 1.3338,\n",
      "         1.7747, 1.1968, 2.3796, 1.4707, 2.0528, 2.0095, 1.0994, 1.7717, 1.8366,\n",
      "         1.4754, 1.5988, 1.2756, 0.7621, 1.9606, 2.0718, 1.4586, 0.8962, 1.3819,\n",
      "         1.7021, 0.9907, 1.4443, 0.7448, 2.0288, 2.2237, 1.2800, 1.0431, 2.3654,\n",
      "         2.8592, 0.5329, 1.8290, 1.3784, 1.2411, 2.2984, 1.4688, 1.6555, 2.4432,\n",
      "         1.2430, 1.1315, 1.5303, 2.1642, 1.5556, 2.2807, 2.2047, 1.9169, 1.7164,\n",
      "         1.7036, 1.6818, 1.5924, 2.5819, 1.0053, 1.6741, 1.5653, 1.2969, 1.9490,\n",
      "         0.9548],\n",
      "        [2.2600, 2.2696, 0.8451, 1.7597, 1.6367, 0.7657, 0.9389, 2.5612, 1.8145,\n",
      "         3.0832, 1.6112, 0.9793, 1.8509, 1.9444, 2.0121, 1.7477, 1.4504, 1.6555,\n",
      "         1.8877, 0.6085, 1.3957, 1.5837, 2.2481, 0.7982, 2.3196, 1.2311, 0.5905,\n",
      "         0.9747, 1.7443, 1.7518, 1.4211, 0.9952, 1.8986, 1.5801, 0.8587, 1.9397,\n",
      "         1.6719, 1.9267, 1.0583, 0.5792, 2.0642, 1.2937, 1.8623, 1.3178, 1.6774,\n",
      "         1.7847, 0.8423, 2.2839, 1.4478, 2.4734, 1.8899, 1.0939, 1.6913, 1.4276,\n",
      "         1.1089, 2.1352, 1.3586, 0.9585, 1.9906, 1.9182, 1.6973, 0.8001, 1.1647,\n",
      "         1.8728, 1.2180, 1.8461, 0.1610, 1.6081, 1.9761, 1.4173, 0.5393, 2.3267,\n",
      "         2.5634, 0.4344, 1.5498, 1.5580, 1.2099, 2.5245, 1.6361, 1.9414, 2.1554,\n",
      "         1.2822, 1.4383, 1.6867, 1.9955, 1.6129, 2.0984, 2.2413, 1.9989, 1.9577,\n",
      "         1.8426, 1.1288, 1.3464, 2.1811, 1.3194, 1.7251, 1.3115, 1.3557, 1.6273,\n",
      "         0.9168]], grad_fn=<SelectBackward>)\n",
      "tensor([[-0.2529,  0.4204, -0.2529,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529,\n",
      "         -0.2529,  0.4204,  0.4204, -0.2529,  0.5270,  0.4204,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204, -0.2529,  0.4204,  0.5270,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "         -0.2529, -0.2529, -0.2529,  0.5270,  0.4204, -0.2529,  0.5270,  0.4204,\n",
      "          0.4204,  0.5270,  0.4204,  0.4204, -0.2529, -0.2529,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204, -0.2529,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.5270,  0.4204, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204, -0.2529,  0.5270,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529, -0.2529, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,  0.4204,  0.5270,\n",
      "         -0.2529,  0.4204, -0.2529,  0.5270],\n",
      "        [-0.2529, -0.2529, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529,  0.5270, -0.2529,\n",
      "          0.4204,  0.5270,  0.4204, -0.2529,  0.5270,  0.4204,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.5270,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "         -0.2529,  0.4204, -0.2529,  0.5270,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.5270,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,\n",
      "          0.4204,  0.5270, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.5270, -0.2529, -0.2529, -0.2529, -0.2529,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529,  0.4204,  0.5270,\n",
      "         -0.2529,  0.4204, -0.2529,  0.5270],\n",
      "        [-0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529,  0.5270,  0.4204,\n",
      "          0.4204,  0.5270, -0.2529,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204, -0.2529,  0.4204, -0.2529, -0.2529,  0.4204,  0.5270,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.5270,  0.4204,  0.5270,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "         -0.2529, -0.2529,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204, -0.2529, -0.2529,  0.4204, -0.2529,\n",
      "          0.5270,  0.4204,  0.4204,  0.4204,  0.5270,  0.4204, -0.2529,  0.5270,\n",
      "          0.4204,  0.4204, -0.2529,  0.5270],\n",
      "        [-0.2529, -0.2529,  0.4204,  0.4204,  0.4204,  0.5270,  0.4204, -0.2529,\n",
      "          0.4204, -0.2529,  0.4204, -0.2529,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "         -0.2529,  0.4204, -0.2529, -0.2529,  0.4204, -0.2529, -0.2529,  0.4204,\n",
      "          0.4204,  0.4204, -0.2529,  0.5270,  0.4204,  0.4204,  0.5270,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204, -0.2529, -0.2529,  0.5270, -0.2529,\n",
      "          0.5270,  0.5270,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529, -0.2529,\n",
      "         -0.2529, -0.2529,  0.5270,  0.5270,  0.4204, -0.2529,  0.4204, -0.2529,\n",
      "         -0.2529,  0.5270,  0.4204, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "          0.4204,  0.5270,  0.4204, -0.2529,  0.4204,  0.4204, -0.2529,  0.4204,\n",
      "         -0.2529,  0.5270, -0.2529,  0.5270],\n",
      "        [-0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204, -0.2529,  0.4204,  0.5270,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.5270,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.5270,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.5270,  0.4204,  0.4204,  0.4204, -0.2529, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204],\n",
      "        [ 0.4204, -0.2529,  0.4204,  0.4204,  0.4204,  0.5270,  0.5270, -0.2529,\n",
      "         -0.2529, -0.2529,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.5270,  0.4204,  0.4204, -0.2529,  0.4204,\n",
      "         -0.2529,  0.4204,  0.5270,  0.5270,  0.4204,  0.4204,  0.4204,  0.5270,\n",
      "          0.4204,  0.4204,  0.5270,  0.4204,  0.4204,  0.4204,  0.4204,  0.5270,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204, -0.2529, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,\n",
      "          0.4204,  0.5270,  0.4204, -0.2529,  0.4204,  0.5270,  0.4204,  0.4204,\n",
      "          0.5270,  0.4204,  0.5270, -0.2529, -0.2529,  0.4204,  0.4204, -0.2529,\n",
      "         -0.2529,  0.5270,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204, -0.2529, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.5270],\n",
      "        [-0.2529, -0.2529,  0.5270,  0.4204,  0.4204,  0.5270,  0.5270, -0.2529,\n",
      "          0.4204, -0.9963,  0.4204,  0.5270,  0.4204,  0.4204, -0.2529,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.5270,  0.4204,  0.4204, -0.2529,  0.5270,\n",
      "         -0.2529,  0.4204,  0.5270,  0.5270,  0.4204,  0.4204,  0.4204,  0.5270,\n",
      "          0.4204,  0.4204,  0.5270,  0.4204,  0.4204,  0.4204,  0.4204,  0.5270,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529,\n",
      "          0.4204, -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,\n",
      "          0.4204,  0.5270,  0.4204,  0.4204,  0.4204,  0.5270,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.5270,  0.4204,  0.4204,  0.4204,  0.5270, -0.2529,\n",
      "         -0.2529,  0.5270,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "         -0.2529,  0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529, -0.2529,\n",
      "          0.4204,  0.4204,  0.4204,  0.4204,  0.4204, -0.2529,  0.4204,  0.4204,\n",
      "          0.4204,  0.4204,  0.4204,  0.5270]], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-887f29f54759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-90b986b10c84>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m#print(embedding.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstmOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstmOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/Midi_Parser/.env3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-90b986b10c84>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embed)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mlstmOut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstmOut'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstmOut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m##################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/Midi_Parser/.env3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/Midi_Parser/.env3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/Midi_Parser/.env3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise RuntimeError(\n\u001b[1;32m    125\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 126\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 4"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'/media/EXTHD/niciData/models/YamahaPianoComp2002_5Epochs_LSTM_noTW.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True, threshold=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "playSeq = 0\n",
    "pathToSampleSeq = \"../DougMcKenzieFiles/train/Mad About the Boy.mid\"\n",
    "if(model.train()):\n",
    "    model.eval()\n",
    "if(autoencoderModel.train()):\n",
    "    autoencoderModel.eval()\n",
    "\n",
    "###PREDICT 8th SEQUENCE\n",
    "with torch.no_grad():\n",
    "    \n",
    "    sampleNp1 = getSlicedPianorollMatrixNp(pathToSampleSeq)\n",
    "    sampleNp1 = deleteZeroMatrices(sampleNp1)\n",
    "    sample = np.expand_dims(sampleNp1[0,:,36:-32],axis=0)\n",
    "    print(sample.shape)\n",
    "    for i, sampleNp in enumerate(sampleNp1[playSeq:playSeq+6]):\n",
    "        #print(sampleNp.shape)\n",
    "        if(np.any(sampleNp)):\n",
    "            sampleNp = sampleNp[:,36:-32]\n",
    "            sampleNp = np.expand_dims(sampleNp,axis=0)\n",
    "            sample = np.concatenate((sample,sampleNp),axis=0)\n",
    "    samplePlay = sample[0,:,:]\n",
    "    for s in sample[1:]:\n",
    "        samplePlay = np.concatenate((samplePlay,s),axis=0)\n",
    "    samplePlay = addCuttedOctaves(samplePlay)\n",
    "    print(samplePlay.shape)\n",
    "    sample = torch.from_numpy(sample).float().to(device)\n",
    "    sample = torch.unsqueeze(sample,1)\n",
    "    print(sample.size())\n",
    "    embed = autoencoderModel.encoder(sample)\n",
    "    #embed = model.splitEmbedding(embed)\n",
    "    embed, lstmOut = model(embed)\n",
    "    print(lstmOut.size())\n",
    "    #pred = autoencoderModel.decoder(lstmOut[0,:,:])\n",
    "    pred = autoencoderModel.decoder(lstmOut)\n",
    "    prediction = pred.squeeze(0).squeeze(0).cpu().numpy()\n",
    "    predict = np.squeeze(prediction, axis=1)\n",
    "    prediction = predict[0,:,:]\n",
    "    print(prediction.shape)\n",
    "    for pred in predict[1:]:\n",
    "        prediction = np.concatenate((prediction, pred), axis =0)\n",
    "    \n",
    "    print(prediction[:,:])\n",
    "    #print(np.sum(sampleNp.numpy(), axis=1))\n",
    "    \n",
    "    #NORMALIZE PREDICTIONS\n",
    "    #reconstruction /= np.abs(np.max(reconstruction))\n",
    "    prediction /= np.abs(np.max(prediction))\n",
    "    #print(prediction)\n",
    "\n",
    "    #CHECK MIDI ACTIVATIONS IN PREDICTION TO INCLUDE RESTS\n",
    "    #reconstruction[reconstruction < 0.3] = 0\n",
    "    prediction[prediction < 0.8] = 0\n",
    "\n",
    "\n",
    "\n",
    "    ###MONOPHONIC OUTPUT MATRIX POLOYPHONIC POSSIBLE WITH ACTIVATION THRESHOLD###\n",
    "    #score = music21.converter.parse(\n",
    "    #'WikifoniaServer/samples/The-Doors---Don\\'t-you-love-her-Madly?.mid')\n",
    "    #score.show()\n",
    "\n",
    "    samplePlay = debinarizeMidi(samplePlay, prediction=False)\n",
    "    samplePlay = addCuttedOctaves(samplePlay)\n",
    "    #reconstruction = debinarizeMidi(reconstruction, prediction=True)\n",
    "    #reconstruction = addCuttedOctaves(reconstruction)\n",
    "    prediction = debinarizeMidi(prediction, prediction=True)\n",
    "    prediction = addCuttedOctaves(prediction)\n",
    "    print(\"INPUT\")\n",
    "    print(samplePlay.shape)\n",
    "    pianorollMatrixToTempMidi(samplePlay, show=True,showPlayer=True,autoplay=False)\n",
    "    #print(\"RECONSTRUCTION\")\n",
    "    #pianorollMatrixToTempMidi(reconstruction, show=True,\n",
    "    #                            showPlayer=True,autoplay=True, prediction=True)\n",
    "    print(\"PREDICTION\")\n",
    "    pianorollMatrixToTempMidi(prediction, prediction=True, \n",
    "                              show=True,showPlayer=True,autoplay=True)        \n",
    "    print(\"\\n\\n\")\n",
    "            \n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
